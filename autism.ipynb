{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "56b1aa06",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import cv2\n",
    "import os\n",
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from zipfile import ZipFile\n",
    "data=\"Autism_vol10.zip\"\n",
    "with ZipFile(data,'r') as zip:\n",
    "  zip.extractall()\n",
    "  print('Done')\n",
    "\n",
    "# Define data paths\n",
    "train_data_dir = 'Autism_vol8/train'\n",
    "validation_data_dir = 'Autism_vol8/validation'\n",
    "test_data_dir = 'Autism_vol8/test'\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b609e6fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "datagen = ImageDataGenerator(\n",
    "    rotation_range=20,\n",
    "    width_shift_range=0.2,\n",
    "    height_shift_range=0.2,\n",
    "    shear_range=0.2,\n",
    "    zoom_range=0.2,\n",
    "    horizontal_flip=True,\n",
    "    fill_mode='nearest'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cca0cdaf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 3518 images belonging to 2 classes.\n",
      "Found 726 images belonging to 2 classes.\n",
      "Found 352 images belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "# Set hyperparameters\n",
    "batch_size = 64\n",
    "epochs = 40\n",
    "image_size = (256, 256)  # Adjust the image size as needed\n",
    "num_classes=2\n",
    "# Data augmentation for training\n",
    "train_datagen = ImageDataGenerator(\n",
    "        rescale=1./255,\n",
    "        zoom_range=0.20,\n",
    "        fill_mode=\"nearest\")\n",
    "validation_datagen = ImageDataGenerator(rescale=1./255)\n",
    "test_datagen = ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "# Start ImageClassification Model\n",
    "train_generator = train_datagen.flow_from_directory(train_data_dir,\n",
    "\n",
    "        target_size=(256, 256),\n",
    "        color_mode='rgb',                                               \n",
    "        batch_size=32,\n",
    "        class_mode='categorical',\n",
    "        subset='training')\n",
    "\n",
    "validation_generator = validation_datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        color_mode='rgb',\n",
    "        target_size=(256, 256),\n",
    "        batch_size=32,\n",
    "        class_mode='categorical',  # only data, no labels\n",
    "        shuffle=False)\n",
    "test_generator = test_datagen.flow_from_directory(\n",
    "    test_data_dir,\n",
    "    target_size=image_size,\n",
    "    batch_size=batch_size,\n",
    "    class_mode='categorical'\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "88764227",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "54/54 [==============================] - 1578s 29s/step - loss: 0.6272 - accuracy: 0.6834 - val_loss: 0.4849 - val_accuracy: 1.0000\n",
      "Epoch 2/40\n",
      "54/54 [==============================] - 1505s 28s/step - loss: 0.6208 - accuracy: 0.6848 - val_loss: 0.3344 - val_accuracy: 1.0000\n",
      "Epoch 3/40\n",
      "54/54 [==============================] - 1518s 28s/step - loss: 0.6030 - accuracy: 0.6802 - val_loss: 0.4488 - val_accuracy: 0.9773\n",
      "Epoch 4/40\n",
      "54/54 [==============================] - 1490s 28s/step - loss: 0.5703 - accuracy: 0.7390 - val_loss: 1.0154 - val_accuracy: 0.4403\n",
      "Epoch 5/40\n",
      "54/54 [==============================] - 1425s 26s/step - loss: 0.5466 - accuracy: 0.7462 - val_loss: 0.7398 - val_accuracy: 0.6676\n",
      "Epoch 6/40\n",
      "54/54 [==============================] - 1444s 27s/step - loss: 0.5621 - accuracy: 0.7373 - val_loss: 0.4895 - val_accuracy: 0.8153\n",
      "Epoch 7/40\n",
      "54/54 [==============================] - 1442s 27s/step - loss: 0.5217 - accuracy: 0.7740 - val_loss: 0.6757 - val_accuracy: 0.7074\n",
      "Epoch 8/40\n",
      "54/54 [==============================] - 1435s 27s/step - loss: 0.5351 - accuracy: 0.7610 - val_loss: 0.4766 - val_accuracy: 0.7955\n",
      "Epoch 9/40\n",
      "54/54 [==============================] - 1440s 27s/step - loss: 0.4868 - accuracy: 0.8027 - val_loss: 0.7119 - val_accuracy: 0.7074\n",
      "Epoch 10/40\n",
      "54/54 [==============================] - 1429s 26s/step - loss: 0.4708 - accuracy: 0.8050 - val_loss: 0.7368 - val_accuracy: 0.7699\n",
      "Epoch 11/40\n",
      "54/54 [==============================] - 1436s 27s/step - loss: 0.4667 - accuracy: 0.8134 - val_loss: 0.7278 - val_accuracy: 0.7528\n",
      "Epoch 12/40\n",
      "54/54 [==============================] - 1443s 27s/step - loss: 0.4548 - accuracy: 0.8189 - val_loss: 0.8159 - val_accuracy: 0.7528\n",
      "Epoch 13/40\n",
      "54/54 [==============================] - 1423s 26s/step - loss: 0.4427 - accuracy: 0.8038 - val_loss: 0.5367 - val_accuracy: 0.7244\n",
      "Epoch 14/40\n",
      "54/54 [==============================] - 1448s 27s/step - loss: 0.4402 - accuracy: 0.8177 - val_loss: 0.8846 - val_accuracy: 0.6051\n",
      "Epoch 15/40\n",
      "54/54 [==============================] - 1417s 26s/step - loss: 0.4183 - accuracy: 0.8314 - val_loss: 1.1364 - val_accuracy: 0.6392\n",
      "Epoch 16/40\n",
      "54/54 [==============================] - 1445s 27s/step - loss: 0.3867 - accuracy: 0.8356 - val_loss: 0.6255 - val_accuracy: 0.7614\n",
      "Epoch 17/40\n",
      "54/54 [==============================] - 1417s 26s/step - loss: 0.4175 - accuracy: 0.8229 - val_loss: 1.4894 - val_accuracy: 0.6392\n",
      "Epoch 18/40\n",
      "54/54 [==============================] - 1447s 27s/step - loss: 0.4036 - accuracy: 0.8299 - val_loss: 1.2654 - val_accuracy: 0.5852\n",
      "Epoch 19/40\n",
      "54/54 [==============================] - 1366s 25s/step - loss: 0.3784 - accuracy: 0.8326 - val_loss: 1.3284 - val_accuracy: 0.5284\n",
      "Epoch 20/40\n",
      "54/54 [==============================] - 849s 16s/step - loss: 0.3791 - accuracy: 0.8355 - val_loss: 1.4691 - val_accuracy: 0.5511\n",
      "Epoch 21/40\n",
      "54/54 [==============================] - 843s 16s/step - loss: 0.3585 - accuracy: 0.8534 - val_loss: 1.3378 - val_accuracy: 0.6051\n",
      "Epoch 22/40\n",
      "54/54 [==============================] - 838s 15s/step - loss: 0.3398 - accuracy: 0.8565 - val_loss: 1.4222 - val_accuracy: 0.6307\n",
      "Epoch 23/40\n",
      "54/54 [==============================] - 845s 16s/step - loss: 0.3157 - accuracy: 0.8662 - val_loss: 1.9940 - val_accuracy: 0.5909\n",
      "Epoch 24/40\n",
      "54/54 [==============================] - 837s 15s/step - loss: 0.3285 - accuracy: 0.8663 - val_loss: 1.1427 - val_accuracy: 0.5625\n",
      "Epoch 25/40\n",
      "54/54 [==============================] - 846s 16s/step - loss: 0.3321 - accuracy: 0.8552 - val_loss: 1.7621 - val_accuracy: 0.5398\n",
      "Epoch 26/40\n",
      "54/54 [==============================] - 838s 16s/step - loss: 0.3112 - accuracy: 0.8715 - val_loss: 2.0058 - val_accuracy: 0.5256\n",
      "Epoch 27/40\n",
      "54/54 [==============================] - 845s 16s/step - loss: 0.3004 - accuracy: 0.8835 - val_loss: 1.3443 - val_accuracy: 0.6875\n",
      "Epoch 28/40\n",
      "54/54 [==============================] - 844s 16s/step - loss: 0.2825 - accuracy: 0.8911 - val_loss: 1.5991 - val_accuracy: 0.5625\n",
      "Epoch 29/40\n",
      "54/54 [==============================] - 838s 16s/step - loss: 0.2939 - accuracy: 0.8808 - val_loss: 1.5527 - val_accuracy: 0.6023\n",
      "Epoch 30/40\n",
      "54/54 [==============================] - 838s 16s/step - loss: 0.2767 - accuracy: 0.8970 - val_loss: 1.5064 - val_accuracy: 0.5682\n",
      "Epoch 31/40\n",
      "54/54 [==============================] - 840s 16s/step - loss: 0.2529 - accuracy: 0.8958 - val_loss: 2.0596 - val_accuracy: 0.5341\n",
      "Epoch 32/40\n",
      "54/54 [==============================] - 845s 16s/step - loss: 0.2545 - accuracy: 0.8999 - val_loss: 1.9195 - val_accuracy: 0.5227\n",
      "Epoch 33/40\n",
      "54/54 [==============================] - 838s 16s/step - loss: 0.2504 - accuracy: 0.9028 - val_loss: 2.7491 - val_accuracy: 0.5227\n",
      "Epoch 34/40\n",
      "54/54 [==============================] - 845s 16s/step - loss: 0.2564 - accuracy: 0.8964 - val_loss: 1.8401 - val_accuracy: 0.5966\n",
      "Epoch 35/40\n",
      "54/54 [==============================] - 845s 16s/step - loss: 0.2324 - accuracy: 0.9103 - val_loss: 1.6198 - val_accuracy: 0.6364\n",
      "Epoch 36/40\n",
      "54/54 [==============================] - 838s 16s/step - loss: 0.2340 - accuracy: 0.9074 - val_loss: 2.0213 - val_accuracy: 0.6534\n",
      "Epoch 37/40\n",
      "54/54 [==============================] - 844s 16s/step - loss: 0.2453 - accuracy: 0.8976 - val_loss: 2.4887 - val_accuracy: 0.4602\n",
      "Epoch 38/40\n",
      "54/54 [==============================] - 840s 16s/step - loss: 0.2461 - accuracy: 0.9062 - val_loss: 1.5434 - val_accuracy: 0.6023\n",
      "Epoch 39/40\n",
      "54/54 [==============================] - 845s 16s/step - loss: 0.2438 - accuracy: 0.9051 - val_loss: 2.9139 - val_accuracy: 0.3580\n",
      "Epoch 40/40\n",
      "54/54 [==============================] - 842s 16s/step - loss: 0.2220 - accuracy: 0.9148 - val_loss: 3.0790 - val_accuracy: 0.4205\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " conv2d_5 (Conv2D)           (None, 254, 254, 128)     3584      \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 252, 252, 64)      73792     \n",
      "                                                                 \n",
      " max_pooling2d_3 (MaxPooling  (None, 84, 84, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 82, 82, 128)       73856     \n",
      "                                                                 \n",
      " conv2d_8 (Conv2D)           (None, 80, 80, 64)        73792     \n",
      "                                                                 \n",
      " max_pooling2d_4 (MaxPooling  (None, 26, 26, 64)       0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_9 (Conv2D)           (None, 24, 24, 64)        36928     \n",
      "                                                                 \n",
      " max_pooling2d_5 (MaxPooling  (None, 8, 8, 64)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_1 (Flatten)         (None, 4096)              0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 256)               1048832   \n",
      "                                                                 \n",
      " dense_4 (Dense)             (None, 128)               32896     \n",
      "                                                                 \n",
      " dense_5 (Dense)             (None, 2)                 258       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,343,938\n",
      "Trainable params: 1,343,938\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "5/5 [==============================] - 26s 5s/step - loss: 1.6923 - accuracy: 0.6344\n",
      "Test accuracy: 0.6343749761581421\n"
     ]
    }
   ],
   "source": [
    "# Create CNN model\n",
    "model = Sequential([\n",
    "    Conv2D(128, (3, 3), activation='relu', input_shape=(image_size[0], image_size[1], 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Conv2D(128, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu' ),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Conv2D(64, (3, 3), activation='relu',),\n",
    "    MaxPooling2D((3, 3)),\n",
    "    Flatten(),\n",
    "    Dense(256, activation='relu'),\n",
    "    Dense(128, activation='relu'),\n",
    "   \n",
    "    Dense(num_classes, activation='softmax')  # num_classes is the number of classes in your dataset\n",
    "])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    steps_per_epoch=train_generator.samples//batch_size,\n",
    "    epochs=epochs,\n",
    "    validation_data=validation_generator,\n",
    "    validation_steps=validation_generator.samples//batch_size\n",
    ")\n",
    "model.summary()\n",
    "# Evaluate the model on the test set\n",
    "test_loss, test_acc = model.evaluate(test_generator, steps=test_generator.samples//batch_size)\n",
    "\n",
    "print(f\"Test accuracy: {test_acc}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "618231da",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image \n",
    "import PIL \n",
    "import matplotlib.pyplot as plt \n",
    "def plot(history):\n",
    "    plt.figure(1) \n",
    "     # summarize history for accuracy  \n",
    " \n",
    "    plt.subplot(211)  \n",
    "    plt.plot(history.history['accuracy'])  \n",
    "    plt.plot(history.history['val_accuracy'])  \n",
    "    plt.title('accuracy vs val_accuracy')  \n",
    "    plt.ylabel('accuracy')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['Train', 'Validation'], loc='lower right')  \n",
    " \n",
    "     # summarize history for loss  \n",
    " \n",
    "    plt.subplot(212)  \n",
    "    plt.plot(history.history['loss'])  \n",
    "    plt.plot(history.history['val_loss'])  \n",
    "    plt.title('loss vs val_loss')  \n",
    "    plt.ylabel('loss')  \n",
    "    plt.xlabel('epoch')  \n",
    "    plt.legend(['Train', 'Validation'], loc='upper right')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1aa8e2e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
